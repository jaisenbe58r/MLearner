{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MLearner's documentation! MLearner is a Python library of useful tools for the day-to-day data science tasks. Links Documentation: https://jaisenbe58r.github.io/MLearner/ Source code repository: https://github.com/jaisenbe58r/MLearner PyPI: https://pypi.python.org/pypi/mlearner Questions? Check out the Discord group MLearner Examples License MIT License Copyright (c) 2020 Jaime Sendra Berenguer Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contact I received a lot of feedback and questions about mlearner recently, and I thought that it would be worthwhile to set up a public communication channel. Before you write an email with a question about mlearner, please consider posting it here since it can also be useful to others! Please join the Discord group MLearner If Google Groups is not for you, please feel free to write me an email or consider filing an issue on GitHub's issue tracker for new feature requests or bug reports. In addition, I setup a Gitter channel for live discussions.","title":"Home"},{"location":"#welcome-to-mlearners-documentation","text":"MLearner is a Python library of useful tools for the day-to-day data science tasks.","title":"Welcome to MLearner's documentation!"},{"location":"#links","text":"Documentation: https://jaisenbe58r.github.io/MLearner/ Source code repository: https://github.com/jaisenbe58r/MLearner PyPI: https://pypi.python.org/pypi/mlearner Questions? Check out the Discord group MLearner","title":"Links"},{"location":"#examples","text":"","title":"Examples"},{"location":"#license","text":"MIT License Copyright (c) 2020 Jaime Sendra Berenguer Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"#contact","text":"I received a lot of feedback and questions about mlearner recently, and I thought that it would be worthwhile to set up a public communication channel. Before you write an email with a question about mlearner, please consider posting it here since it can also be useful to others! Please join the Discord group MLearner If Google Groups is not for you, please feel free to write me an email or consider filing an issue on GitHub's issue tracker for new feature requests or bug reports. In addition, I setup a Gitter channel for live discussions.","title":"Contact"},{"location":"CHANGELOG/","text":"Release Notes The CHANGELOG for the current development version is available at https://github.com/jaisenbe58r/MLearner/blob/master/docs/sources/CHANGELOG.md . Version 0.1.0 (2020-04-17) First Version","title":"Release Notes"},{"location":"CHANGELOG/#release-notes","text":"The CHANGELOG for the current development version is available at https://github.com/jaisenbe58r/MLearner/blob/master/docs/sources/CHANGELOG.md .","title":"Release Notes"},{"location":"CHANGELOG/#version-010-2020-04-17","text":"First Version","title":"Version 0.1.0 (2020-04-17)"},{"location":"CONTRIBUTING/","text":"How to Contribute I would be very happy about any kind of contributions that help to improve and extend the functionality of mlearner. Quick Contributor Checklist This is a quick checklist about the different steps of a typical contribution to mlearner (and other open source projects). Consider copying this list to a local text file (or the issue tracker) and checking off items as you go. [ ] Open a new \"issue\" on GitHub to discuss the new feature / bug fix [ ] Fork the mlearner repository from GitHub (if not already done earlier) [ ] Create and check out a new topic branch (please don't make modifications in the master branch) [ ] Implement the new feature or apply the bug-fix [ ] Add appropriate unit test functions in mlearner/*/tests [ ] Run PYTHONPATH='.' pytest ./mlearner -sv and make sure that all unit tests pass [ ] Check for style issues by running flake8 ./mlearner (you may want to run pytest again after you made modifications to the code) [ ] Add a note about the modification/contribution to the ./docs/sources/changelog.md file [ ] Modify documentation in the appropriate location under mlearner/docs/sources/ [ ] Push the topic branch to the server and create a pull request [ ] Check the Travis-CI build passed at https://travis-ci.org/jaisenbe58r/mlearner [ ] Check/improve the unit test coverage at https://coveralls.io/github/jaisenbe58r/mlearner [ ] Check/improve the code health at https://landscape.io/github/jaisenbe58r/mlearner Tips for Contributors Getting Started - Creating a New Issue and Forking the Repository If you don't have a GitHub account, yet, please create one to contribute to this project. Please submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation. Fork the mlearner repository from the GitHub web interface. Clone the mlearner repository to your local machine by executing git clone https://github.com/<your_username>/MLearner.git Syncing an Existing Fork If you already forked mlearner earlier, you can bring you \"Fork\" up to date with the master branch as follows: 1. Configuring a remote that points to the upstream repository on GitHub List the current configured remote repository of your fork by executing $ git remote -v If you see something like origin https://github.com/<your username>/MLearner.git (fetch) origin https://github.com/<your username>/MLearner.git (push) you need to specify a new remote upstream repository via $ git remote add upstream https://github.com/jaisenbe58r/MLearner.git Now, verify the new upstream repository you've specified for your fork by executing $ git remote -v You should see following output if everything is configured correctly: origin https://github.com/<your username>/MLearner.git (fetch) origin https://github.com/<your username>/MLearner.git (push) upstream https://github.com/jaisenbe58r/MLearner.git (fetch) upstream https://github.com/jaisenbe58r/MLearner.git (push) 2. Syncing your Fork First, fetch the updates of the original project's master branch by executing: $ git fetch upstream You should see the following output remote: Counting objects: xx, done. remote: Compressing objects: 100% (xx/xx), done. remote: Total xx (delta xx), reused xx (delta x) Unpacking objects: 100% (xx/xx), done. From https://github.com/jaisenbe58r/MLearner * [new branch] master -> upstream/master This means that the commits to the jaisenbe58r/mlearner master branch are now stored in the local branch upstream/master . If you are not already on your local project's master branch, execute $ git checkout master Finally, merge the changes in upstream/master to your local master branch by executing $ git merge upstream/master which will give you an output that looks similar to Updating xxx...xxx Fast-forward SOME FILE1 | 12 +++++++ SOME FILE2 | 10 +++++++ 2 files changed, 22 insertions(+), *The Main Workflow - Making Changes in a New Topic Branch Listed below are the 9 typical steps of a contribution. 1. Discussing the Feature or Modification Before you start coding, please discuss the new feature, bugfix, or other modification to the project on the project's issue tracker . Before you open a \"new issue,\" please do a quick search to see if a similar issue has been submitted already. 2. Creating a new feature branch Please avoid working directly on the master branch but create a new feature branch: $ git branch <new_feature> Switch to the new feature branch by executing $ git checkout <new_feature> 3. Developing the new feature / bug fix Now it's time to modify existing code or to contribute new code to the project. 4. Testing your code Add the respective unit tests and check if they pass: $ PYTHONPATH='.' pytest ./mlearner ---with-coverage 5. Documenting changes Please add an entry to the mlearner/docs/sources/changelog.md file. If it is a new feature, it would also be nice if you could update the documentation in appropriate location in mlearner/sources . 6. Committing changes When you are ready to commit the changes, please provide a meaningful commit message: $ git add <modifies_files> # or `git add .` $ git commit -m '<meaningful commit message>' 7. Optional: squashing commits If you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via Note Due to the improved GitHub UI, this is no longer necessary/encouraged. $ git log which will list the commits from newest to oldest in the following format by default: commit 046e3af8a9127df8eac879454f029937c8a31c41 Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 03:46:37 2015 -0500 fixed setup.py commit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 03:04:39 2015 -0500 documented feature x commit d87934fe8726c46f0b166d6290a3bf38915d6e75 Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 02:44:45 2015 -0500 added support for feature x Assuming that it would make sense to group these 3 commits into one, we can execute $ git rebase -i HEAD~3 which will bring our default git editor with the following contents: pick d87934f added support for feature x pick c3c00f6 documented feature x pick 046e3af fixed setup.py Since c3c00f6 and 046e3af are related to the original commit of feature x , let's keep the d87934f and squash the 2 following commits into this initial one by changes the lines to pick d87934f added support for feature x squash c3c00f6 documented feature x squash 046e3af fixed setup.py Now, save the changes in your editor. Now, quitting the editor will apply the rebase changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter support for feature x to summarize the contributions. 8. Uploading changes Push your changes to a topic branch to the git server by executing: $ git push origin <feature_branch> 9. Submitting a pull request Go to your GitHub repository online, select the new feature branch, and submit a new pull request: Notes for Developers Building the documentation The documentation is built via MkDocs ; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing mkdocs serve from the mlearner/docs directory. For example, ~/github/mlearner/docs$ mkdocs serve 1. Building the API documentation To build the API documentation, navigate to mlearner/docs and execute the make_api.py file from this directory via ~/github/mlearner/docs$ python make_api.py This should place the API documentation into the correct directories into the two directories: mlearner/docs/sources/api_modules mlearner/docs/sources/api_subpackes 2. Editing the User Guide The documents containing code examples for the \"User Guide\" are generated from IPython Notebook files. In order to convert a IPython notebook file to markdown after editing, please follow the following steps: Modify or edit the existing notebook. Execute all cells in the current notebook and make sure that no errors occur. Convert the notebook to markdown using the ipynb2markdown.py converter ~/github/mlearner/docs$ python ipynb2markdown.py --ipynb_path ./sources/user_guide/subpackage/notebookname.ipynb Note If you are adding a new document, please also include it in the pages section in the mlearner/docs/mkdocs.yml file. 3. Building static HTML files of the documentation First, please check the documenation via localhost (http://127.0.0.1:8000/): ~/github/mlearner/docs$ mkdocs serve Next, build the static HTML files of the mlearner documentation via ~/github/mlearner/docs$ mkdocs build --clean To deploy the documentation, execute ~/github/mlearner/docs$ mkdocs gh-deploy --clean 4. Generate a PDF of the documentation To generate a PDF version of the documentation, simply cd into the mlearner/docs directory and execute: python md2pdf.py Uploading a new version to PyPI 1. Creating a new testing environment Assuming we are using conda , create a new python environment via $ conda create -n 'mlearner-testing' python=3 numpy scipy pandas Next, activate the environment by executing $ source activate mlearner-testing 2. Installing the package from local files Test the installation by executing $ python setup.py install --record files.txt the --record files.txt flag will create a files.txt file listing the locations where these files will be installed. Try to import the package to see if it works, for example, by executing $ python -c 'import mlearner; print(mlearner.__file__)' If everything seems to be fine, remove the installation via $ cat files.txt | xargs rm -rf ; rm files.txt Next, test if pip is able to install the packages. First, navigate to a different directory, and from there, install the package: $ pip install mlearner and uninstall it again $ pip uninstall mlearner 3. Deploying the package Consider deploying the package to the PyPI test server first. The setup instructions can be found here . $ python setup.py sdist bdist_wheel upload -r https://testpypi.python.org/pypi Test if it can be installed from there by executing $ pip install -i https://testpypi.python.org/pypi mlearner and uninstall it $ pip uninstall mlearner After this dry-run succeeded, repeat this process using the \"real\" PyPI: $ python setup.py sdist bdist_wheel upload 4. Removing the virtual environment Finally, to cleanup our local drive, remove the virtual testing environment via $ conda remove --name 'mlearner-testing' --all 5. Updating the conda-forge recipe Once a new version of mlearner has been uploaded to PyPI, update the conda-forge build recipe at https://github.com/conda-forge/mlearner-feedstock by changing the version number in the recipe/meta.yaml file appropriately.","title":"How To Contribute"},{"location":"CONTRIBUTING/#how-to-contribute","text":"I would be very happy about any kind of contributions that help to improve and extend the functionality of mlearner.","title":"How to Contribute"},{"location":"CONTRIBUTING/#quick-contributor-checklist","text":"This is a quick checklist about the different steps of a typical contribution to mlearner (and other open source projects). Consider copying this list to a local text file (or the issue tracker) and checking off items as you go. [ ] Open a new \"issue\" on GitHub to discuss the new feature / bug fix [ ] Fork the mlearner repository from GitHub (if not already done earlier) [ ] Create and check out a new topic branch (please don't make modifications in the master branch) [ ] Implement the new feature or apply the bug-fix [ ] Add appropriate unit test functions in mlearner/*/tests [ ] Run PYTHONPATH='.' pytest ./mlearner -sv and make sure that all unit tests pass [ ] Check for style issues by running flake8 ./mlearner (you may want to run pytest again after you made modifications to the code) [ ] Add a note about the modification/contribution to the ./docs/sources/changelog.md file [ ] Modify documentation in the appropriate location under mlearner/docs/sources/ [ ] Push the topic branch to the server and create a pull request [ ] Check the Travis-CI build passed at https://travis-ci.org/jaisenbe58r/mlearner [ ] Check/improve the unit test coverage at https://coveralls.io/github/jaisenbe58r/mlearner [ ] Check/improve the code health at https://landscape.io/github/jaisenbe58r/mlearner","title":"Quick Contributor Checklist"},{"location":"CONTRIBUTING/#tips-for-contributors","text":"","title":"Tips for Contributors"},{"location":"CONTRIBUTING/#getting-started-creating-a-new-issue-and-forking-the-repository","text":"If you don't have a GitHub account, yet, please create one to contribute to this project. Please submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation. Fork the mlearner repository from the GitHub web interface. Clone the mlearner repository to your local machine by executing git clone https://github.com/<your_username>/MLearner.git","title":"Getting Started - Creating a New Issue and Forking the Repository"},{"location":"CONTRIBUTING/#syncing-an-existing-fork","text":"If you already forked mlearner earlier, you can bring you \"Fork\" up to date with the master branch as follows:","title":"Syncing an Existing Fork"},{"location":"CONTRIBUTING/#1-configuring-a-remote-that-points-to-the-upstream-repository-on-github","text":"List the current configured remote repository of your fork by executing $ git remote -v If you see something like origin https://github.com/<your username>/MLearner.git (fetch) origin https://github.com/<your username>/MLearner.git (push) you need to specify a new remote upstream repository via $ git remote add upstream https://github.com/jaisenbe58r/MLearner.git Now, verify the new upstream repository you've specified for your fork by executing $ git remote -v You should see following output if everything is configured correctly: origin https://github.com/<your username>/MLearner.git (fetch) origin https://github.com/<your username>/MLearner.git (push) upstream https://github.com/jaisenbe58r/MLearner.git (fetch) upstream https://github.com/jaisenbe58r/MLearner.git (push)","title":"1. Configuring a remote that points to the upstream repository on GitHub"},{"location":"CONTRIBUTING/#2-syncing-your-fork","text":"First, fetch the updates of the original project's master branch by executing: $ git fetch upstream You should see the following output remote: Counting objects: xx, done. remote: Compressing objects: 100% (xx/xx), done. remote: Total xx (delta xx), reused xx (delta x) Unpacking objects: 100% (xx/xx), done. From https://github.com/jaisenbe58r/MLearner * [new branch] master -> upstream/master This means that the commits to the jaisenbe58r/mlearner master branch are now stored in the local branch upstream/master . If you are not already on your local project's master branch, execute $ git checkout master Finally, merge the changes in upstream/master to your local master branch by executing $ git merge upstream/master which will give you an output that looks similar to Updating xxx...xxx Fast-forward SOME FILE1 | 12 +++++++ SOME FILE2 | 10 +++++++ 2 files changed, 22 insertions(+),","title":"2. Syncing your Fork"},{"location":"CONTRIBUTING/#the-main-workflow-making-changes-in-a-new-topic-branch","text":"Listed below are the 9 typical steps of a contribution.","title":"*The Main Workflow - Making Changes in a New Topic Branch"},{"location":"CONTRIBUTING/#1-discussing-the-feature-or-modification","text":"Before you start coding, please discuss the new feature, bugfix, or other modification to the project on the project's issue tracker . Before you open a \"new issue,\" please do a quick search to see if a similar issue has been submitted already.","title":"1. Discussing the Feature or Modification"},{"location":"CONTRIBUTING/#2-creating-a-new-feature-branch","text":"Please avoid working directly on the master branch but create a new feature branch: $ git branch <new_feature> Switch to the new feature branch by executing $ git checkout <new_feature>","title":"2. Creating a new feature branch"},{"location":"CONTRIBUTING/#3-developing-the-new-feature-bug-fix","text":"Now it's time to modify existing code or to contribute new code to the project.","title":"3. Developing the new feature / bug fix"},{"location":"CONTRIBUTING/#4-testing-your-code","text":"Add the respective unit tests and check if they pass: $ PYTHONPATH='.' pytest ./mlearner ---with-coverage","title":"4. Testing your code"},{"location":"CONTRIBUTING/#5-documenting-changes","text":"Please add an entry to the mlearner/docs/sources/changelog.md file. If it is a new feature, it would also be nice if you could update the documentation in appropriate location in mlearner/sources .","title":"5. Documenting changes"},{"location":"CONTRIBUTING/#6-committing-changes","text":"When you are ready to commit the changes, please provide a meaningful commit message: $ git add <modifies_files> # or `git add .` $ git commit -m '<meaningful commit message>'","title":"6. Committing changes"},{"location":"CONTRIBUTING/#7-optional-squashing-commits","text":"If you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via Note Due to the improved GitHub UI, this is no longer necessary/encouraged. $ git log which will list the commits from newest to oldest in the following format by default: commit 046e3af8a9127df8eac879454f029937c8a31c41 Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 03:46:37 2015 -0500 fixed setup.py commit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 03:04:39 2015 -0500 documented feature x commit d87934fe8726c46f0b166d6290a3bf38915d6e75 Author: jaisenbe58r <jaisenberafel@gmail.com> Date: Tue Nov 24 02:44:45 2015 -0500 added support for feature x Assuming that it would make sense to group these 3 commits into one, we can execute $ git rebase -i HEAD~3 which will bring our default git editor with the following contents: pick d87934f added support for feature x pick c3c00f6 documented feature x pick 046e3af fixed setup.py Since c3c00f6 and 046e3af are related to the original commit of feature x , let's keep the d87934f and squash the 2 following commits into this initial one by changes the lines to pick d87934f added support for feature x squash c3c00f6 documented feature x squash 046e3af fixed setup.py Now, save the changes in your editor. Now, quitting the editor will apply the rebase changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter support for feature x to summarize the contributions.","title":"7. Optional: squashing commits"},{"location":"CONTRIBUTING/#8-uploading-changes","text":"Push your changes to a topic branch to the git server by executing: $ git push origin <feature_branch>","title":"8. Uploading changes"},{"location":"CONTRIBUTING/#9-submitting-a-pull-request","text":"Go to your GitHub repository online, select the new feature branch, and submit a new pull request:","title":"9. Submitting a pull request"},{"location":"CONTRIBUTING/#notes-for-developers","text":"","title":"Notes for Developers"},{"location":"CONTRIBUTING/#building-the-documentation","text":"The documentation is built via MkDocs ; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing mkdocs serve from the mlearner/docs directory. For example, ~/github/mlearner/docs$ mkdocs serve","title":"Building the documentation"},{"location":"CONTRIBUTING/#1-building-the-api-documentation","text":"To build the API documentation, navigate to mlearner/docs and execute the make_api.py file from this directory via ~/github/mlearner/docs$ python make_api.py This should place the API documentation into the correct directories into the two directories: mlearner/docs/sources/api_modules mlearner/docs/sources/api_subpackes","title":"1. Building the API documentation"},{"location":"CONTRIBUTING/#2-editing-the-user-guide","text":"The documents containing code examples for the \"User Guide\" are generated from IPython Notebook files. In order to convert a IPython notebook file to markdown after editing, please follow the following steps: Modify or edit the existing notebook. Execute all cells in the current notebook and make sure that no errors occur. Convert the notebook to markdown using the ipynb2markdown.py converter ~/github/mlearner/docs$ python ipynb2markdown.py --ipynb_path ./sources/user_guide/subpackage/notebookname.ipynb Note If you are adding a new document, please also include it in the pages section in the mlearner/docs/mkdocs.yml file.","title":"2. Editing the User Guide"},{"location":"CONTRIBUTING/#3-building-static-html-files-of-the-documentation","text":"First, please check the documenation via localhost (http://127.0.0.1:8000/): ~/github/mlearner/docs$ mkdocs serve Next, build the static HTML files of the mlearner documentation via ~/github/mlearner/docs$ mkdocs build --clean To deploy the documentation, execute ~/github/mlearner/docs$ mkdocs gh-deploy --clean","title":"3. Building static HTML files of the documentation"},{"location":"CONTRIBUTING/#4-generate-a-pdf-of-the-documentation","text":"To generate a PDF version of the documentation, simply cd into the mlearner/docs directory and execute: python md2pdf.py","title":"4. Generate a PDF of the documentation"},{"location":"CONTRIBUTING/#uploading-a-new-version-to-pypi","text":"","title":"Uploading a new version to PyPI"},{"location":"CONTRIBUTING/#1-creating-a-new-testing-environment","text":"Assuming we are using conda , create a new python environment via $ conda create -n 'mlearner-testing' python=3 numpy scipy pandas Next, activate the environment by executing $ source activate mlearner-testing","title":"1. Creating a new testing environment"},{"location":"CONTRIBUTING/#2-installing-the-package-from-local-files","text":"Test the installation by executing $ python setup.py install --record files.txt the --record files.txt flag will create a files.txt file listing the locations where these files will be installed. Try to import the package to see if it works, for example, by executing $ python -c 'import mlearner; print(mlearner.__file__)' If everything seems to be fine, remove the installation via $ cat files.txt | xargs rm -rf ; rm files.txt Next, test if pip is able to install the packages. First, navigate to a different directory, and from there, install the package: $ pip install mlearner and uninstall it again $ pip uninstall mlearner","title":"2. Installing the package from local files"},{"location":"CONTRIBUTING/#3-deploying-the-package","text":"Consider deploying the package to the PyPI test server first. The setup instructions can be found here . $ python setup.py sdist bdist_wheel upload -r https://testpypi.python.org/pypi Test if it can be installed from there by executing $ pip install -i https://testpypi.python.org/pypi mlearner and uninstall it $ pip uninstall mlearner After this dry-run succeeded, repeat this process using the \"real\" PyPI: $ python setup.py sdist bdist_wheel upload","title":"3. Deploying the package"},{"location":"CONTRIBUTING/#4-removing-the-virtual-environment","text":"Finally, to cleanup our local drive, remove the virtual testing environment via $ conda remove --name 'mlearner-testing' --all","title":"4. Removing the virtual environment"},{"location":"CONTRIBUTING/#5-updating-the-conda-forge-recipe","text":"Once a new version of mlearner has been uploaded to PyPI, update the conda-forge build recipe at https://github.com/conda-forge/mlearner-feedstock by changing the version number in the recipe/meta.yaml file appropriately.","title":"5. Updating the conda-forge recipe"},{"location":"USER_GUIDE_INDEX/","text":"User Guide Index data wine_data preprocessing MeanCenterer minmax_scaling FeatureDropper FillNaTransformer_median FillNaTransformer_mean FillNaTransformer_idmax FillNaTransformer_any FillNaTransformer_all FillNaTransformer_value FillNaTransformer_backward FillNaTransformer_forward FixSkewness OneHotEncoder DropOutliers ExtractCategories ReplaceMulticlass ReplaceTransformer DataCleaner DataAnalyst load DataLoad externals NotFittedError","title":"User Guide Index"},{"location":"USER_GUIDE_INDEX/#user-guide-index","text":"","title":"User Guide Index"},{"location":"USER_GUIDE_INDEX/#data","text":"wine_data","title":"data"},{"location":"USER_GUIDE_INDEX/#preprocessing","text":"MeanCenterer minmax_scaling FeatureDropper FillNaTransformer_median FillNaTransformer_mean FillNaTransformer_idmax FillNaTransformer_any FillNaTransformer_all FillNaTransformer_value FillNaTransformer_backward FillNaTransformer_forward FixSkewness OneHotEncoder DropOutliers ExtractCategories ReplaceMulticlass ReplaceTransformer DataCleaner DataAnalyst","title":"preprocessing"},{"location":"USER_GUIDE_INDEX/#load","text":"DataLoad","title":"load"},{"location":"USER_GUIDE_INDEX/#externals","text":"NotFittedError","title":"externals"},{"location":"cite/","text":"Citing mlearner","title":"Citing mlearner"},{"location":"cite/#citing-mlearner","text":"","title":"Citing mlearner"},{"location":"contributors/","text":"Contributors For the current list of contributors to mlearner, please see the GitHub contributor page at [https://github.com/jaisenbe58r/MLearner/graphs/contributors].","title":"Contributors"},{"location":"contributors/#contributors","text":"For the current list of contributors to mlearner, please see the GitHub contributor page at [https://github.com/jaisenbe58r/MLearner/graphs/contributors].","title":"Contributors"},{"location":"discuss/","text":"Discuss Any questions or comments about mlearner? Join the mlearner mailing list on Google Groups!","title":"Discuss"},{"location":"discuss/#discuss","text":"Any questions or comments about mlearner? Join the mlearner mailing list on Google Groups!","title":"Discuss"},{"location":"installation/","text":"Installing mlearner PyPI To install mlearner, just execute pip install mlearner Alternatively, you download the package manually from the Python Package Index https://pypi.python.org/pypi/mlearner , unzip it, navigate into the package, and use the command: python setup.py install Upgrading via pip To upgrade an existing version of mlearner from PyPI, execute pip install mlearner --upgrade --no-deps Please note that the dependencies (NumPy and SciPy) will also be upgraded if you omit the --no-deps flag; use the --no-deps (\"no dependencies\") flag if you don't want this. Installing mlearner from the source distribution In rare cases, users reported problems on certain systems with the default pip installation command, which installs mlearner from the binary distribution (\"wheels\") on PyPI. If you should encounter similar problems, you could try to install mlearner from the source distribution instead via pip install --no-binary :all: mlearner Also, I would appreciate it if you could report any issues that occur when using pip install mlearner in hope that we can fix these in future releases. Conda The mlearner package is also available through conda forge . To install mlearner using conda, use the following command: conda install mlearner --channel conda-forge or simply conda install mlearner if you added conda-forge to your channels ( conda config --add channels conda-forge ). Dev Version The mlearner version on PyPI may always one step behind; you can install the latest development version from the GitHub repository by executing pip install git+git://github.com/jaisenbe58r/MLearner.git Or, you can fork the GitHub repository from https://github.com/jaisenbe58r/MLearner and install mlearner from your local drive via python setup.py install","title":"Installation"},{"location":"installation/#installing-mlearner","text":"","title":"Installing mlearner"},{"location":"installation/#pypi","text":"To install mlearner, just execute pip install mlearner Alternatively, you download the package manually from the Python Package Index https://pypi.python.org/pypi/mlearner , unzip it, navigate into the package, and use the command: python setup.py install","title":"PyPI"},{"location":"installation/#upgrading-via-pip","text":"To upgrade an existing version of mlearner from PyPI, execute pip install mlearner --upgrade --no-deps Please note that the dependencies (NumPy and SciPy) will also be upgraded if you omit the --no-deps flag; use the --no-deps (\"no dependencies\") flag if you don't want this.","title":"Upgrading via pip"},{"location":"installation/#installing-mlearner-from-the-source-distribution","text":"In rare cases, users reported problems on certain systems with the default pip installation command, which installs mlearner from the binary distribution (\"wheels\") on PyPI. If you should encounter similar problems, you could try to install mlearner from the source distribution instead via pip install --no-binary :all: mlearner Also, I would appreciate it if you could report any issues that occur when using pip install mlearner in hope that we can fix these in future releases.","title":"Installing mlearner from the source distribution"},{"location":"installation/#conda","text":"The mlearner package is also available through conda forge . To install mlearner using conda, use the following command: conda install mlearner --channel conda-forge or simply conda install mlearner if you added conda-forge to your channels ( conda config --add channels conda-forge ).","title":"Conda"},{"location":"installation/#dev-version","text":"The mlearner version on PyPI may always one step behind; you can install the latest development version from the GitHub repository by executing pip install git+git://github.com/jaisenbe58r/MLearner.git Or, you can fork the GitHub repository from https://github.com/jaisenbe58r/MLearner and install mlearner from your local drive via python setup.py install","title":"Dev Version"},{"location":"license/","text":"This project is released under a permissive new BSD open source license and commercially usable. There is no warranty; not even for merchantability or fitness for a particular purpose. In addition, you may use, copy, modify, and redistribute all artistic creative works (figures and images) included in this distribution under the directory according to the terms and conditions of the Creative Commons Attribution 4.0 International License. (Computer-generated graphics such as the plots produced by matplotlib fall under the BSD license mentioned above). new BSD License New BSD License Copyright (c) 2014-2020, Sebastian Raschka. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of mlearner nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Creative Commons Attribution 4.0 International License mlearner documentation figures are licensed under a Creative Commons Attribution 4.0 International License. http://creativecommons.org/licenses/by-sa/4.0/ . You are free to: Share \u2014 copy and redistribute the material in any medium or format Adapt \u2014 remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"License"},{"location":"license/#new-bsd-license","text":"New BSD License Copyright (c) 2014-2020, Sebastian Raschka. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of mlearner nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"new BSD License"},{"location":"license/#creative-commons-attribution-40-international-license","text":"mlearner documentation figures are licensed under a Creative Commons Attribution 4.0 International License. http://creativecommons.org/licenses/by-sa/4.0/ .","title":"Creative Commons Attribution 4.0 International License"},{"location":"license/#you-are-free-to","text":"Share \u2014 copy and redistribute the material in any medium or format Adapt \u2014 remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms.","title":"You are free to:"},{"location":"license/#under-the-following-terms","text":"Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"Under the following terms:"},{"location":"api_modules/mlearner.data/create_dataset/","text":"create_dataset create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/","title":"Create dataset"},{"location":"api_modules/mlearner.data/create_dataset/#create_dataset","text":"create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/","title":"create_dataset"},{"location":"api_modules/mlearner.data/data_gamma/","text":"data_gamma data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/","title":"Data gamma"},{"location":"api_modules/mlearner.data/data_gamma/#data_gamma","text":"data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/","title":"data_gamma"},{"location":"api_modules/mlearner.data/data_normal/","text":"data_normal data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/","title":"Data normal"},{"location":"api_modules/mlearner.data/data_normal/#data_normal","text":"data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/","title":"data_normal"},{"location":"api_modules/mlearner.data/data_uniform/","text":"data_uniform data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/","title":"Data uniform"},{"location":"api_modules/mlearner.data/data_uniform/#data_uniform","text":"data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/","title":"data_uniform"},{"location":"api_modules/mlearner.data/wine_data/","text":"wine_data wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/data/wine.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"Wine data"},{"location":"api_modules/mlearner.data/wine_data/#wine_data","text":"wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/data/wine.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"wine_data"},{"location":"api_modules/mlearner.load/DataLoad/","text":"DataLoad DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ Methods load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"DataLoad"},{"location":"api_modules/mlearner.load/DataLoad/#dataload","text":"DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/","title":"DataLoad"},{"location":"api_modules/mlearner.load/DataLoad/#methods","text":"load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/DataAnalyst/","text":"DataAnalyst DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/ Methods boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None","title":"DataAnalyst"},{"location":"api_modules/mlearner.preprocessing/DataAnalyst/#dataanalyst","text":"DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/","title":"DataAnalyst"},{"location":"api_modules/mlearner.preprocessing/DataAnalyst/#methods","text":"boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/DataCleaner/","text":"DataCleaner DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/ Methods categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe","title":"DataCleaner"},{"location":"api_modules/mlearner.preprocessing/DataCleaner/#datacleaner","text":"DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/","title":"DataCleaner"},{"location":"api_modules/mlearner.preprocessing/DataCleaner/#methods","text":"categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/DropOutliers/","text":"DropOutliers DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"DropOutliers"},{"location":"api_modules/mlearner.preprocessing/DropOutliers/#dropoutliers","text":"DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/","title":"DropOutliers"},{"location":"api_modules/mlearner.preprocessing/DropOutliers/#methods","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/ExtractCategories/","text":"ExtractCategories ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ExtractCategories"},{"location":"api_modules/mlearner.preprocessing/ExtractCategories/#extractcategories","text":"ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ExtractCategories"},{"location":"api_modules/mlearner.preprocessing/ExtractCategories/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FeatureDropper/","text":"FeatureDropper FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"FeatureDropper"},{"location":"api_modules/mlearner.preprocessing/FeatureDropper/#featuredropper","text":"FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/","title":"FeatureDropper"},{"location":"api_modules/mlearner.preprocessing/FeatureDropper/#methods","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_all/","text":"FillNaTransformer_all FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer all"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_all/#fillnatransformer_all","text":"FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/","title":"FillNaTransformer_all"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_all/#methods","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_any/","text":"FillNaTransformer_any FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer any"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_any/#fillnatransformer_any","text":"FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/","title":"FillNaTransformer_any"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_any/#methods","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_backward/","text":"FillNaTransformer_backward FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer backward"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_backward/#fillnatransformer_backward","text":"FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/","title":"FillNaTransformer_backward"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_backward/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_forward/","text":"FillNaTransformer_forward FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer forward"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_forward/#fillnatransformer_forward","text":"FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/","title":"FillNaTransformer_forward"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_forward/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_idmax/","text":"FillNaTransformer_idmax FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer idmax"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_idmax/#fillnatransformer_idmax","text":"FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/","title":"FillNaTransformer_idmax"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_idmax/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_mean/","text":"FillNaTransformer_mean FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer mean"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_mean/#fillnatransformer_mean","text":"FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/","title":"FillNaTransformer_mean"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_mean/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_median/","text":"FillNaTransformer_median FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer median"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_median/#fillnatransformer_median","text":"FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/","title":"FillNaTransformer_median"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_median/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_value/","text":"FillNaTransformer_value FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/ Methods fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer value"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_value/#fillnatransformer_value","text":"FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/","title":"FillNaTransformer_value"},{"location":"api_modules/mlearner.preprocessing/FillNaTransformer_value/#methods","text":"fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/FixSkewness/","text":"FixSkewness FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/ Methods fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"FixSkewness"},{"location":"api_modules/mlearner.preprocessing/FixSkewness/#fixskewness","text":"FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/","title":"FixSkewness"},{"location":"api_modules/mlearner.preprocessing/FixSkewness/#methods","text":"fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/MeanCenterer/","text":"MeanCenterer MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause Methods fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"MeanCenterer"},{"location":"api_modules/mlearner.preprocessing/MeanCenterer/#meancenterer","text":"MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause","title":"MeanCenterer"},{"location":"api_modules/mlearner.preprocessing/MeanCenterer/#methods","text":"fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/OneHotEncoder/","text":"OneHotEncoder OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/ Methods fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder.","title":"OneHotEncoder"},{"location":"api_modules/mlearner.preprocessing/OneHotEncoder/#onehotencoder","text":"OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/","title":"OneHotEncoder"},{"location":"api_modules/mlearner.preprocessing/OneHotEncoder/#methods","text":"fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/ReplaceMulticlass/","text":"ReplaceMulticlass ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ReplaceMulticlass"},{"location":"api_modules/mlearner.preprocessing/ReplaceMulticlass/#replacemulticlass","text":"ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/","title":"ReplaceMulticlass"},{"location":"api_modules/mlearner.preprocessing/ReplaceMulticlass/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/ReplaceTransformer/","text":"ReplaceTransformer ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ReplaceTransformer"},{"location":"api_modules/mlearner.preprocessing/ReplaceTransformer/#replacetransformer","text":"ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ReplaceTransformer"},{"location":"api_modules/mlearner.preprocessing/ReplaceTransformer/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_modules/mlearner.preprocessing/minmax_scaling/","text":"minmax_scaling minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"Minmax scaling"},{"location":"api_modules/mlearner.preprocessing/minmax_scaling/#minmax_scaling","text":"minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"minmax_scaling"},{"location":"api_subpackages/mlearner.data/","text":"mlearner version: 0.1.2dev1 create_dataset create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/ data_gamma data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/ data_normal data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/ data_uniform data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/ wine_data wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/data/wine.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"Mlearner.data"},{"location":"api_subpackages/mlearner.data/#create_dataset","text":"create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/","title":"create_dataset"},{"location":"api_subpackages/mlearner.data/#data_gamma","text":"data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/","title":"data_gamma"},{"location":"api_subpackages/mlearner.data/#data_normal","text":"data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/","title":"data_normal"},{"location":"api_subpackages/mlearner.data/#data_uniform","text":"data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/","title":"data_uniform"},{"location":"api_subpackages/mlearner.data/#wine_data","text":"wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/data/wine.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"wine_data"},{"location":"api_subpackages/mlearner.load/","text":"mlearner version: 0.1.2dev1 DataLoad DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ Methods load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"Mlearner.load"},{"location":"api_subpackages/mlearner.load/#dataload","text":"DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/","title":"DataLoad"},{"location":"api_subpackages/mlearner.load/#methods","text":"load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/","text":"mlearner version: 0.1.2dev1 DataAnalyst DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/ Methods boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None DataCleaner DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/ Methods categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe DropOutliers DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped. ExtractCategories ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FeatureDropper FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped. FillNaTransformer_all FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_any FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_backward FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_forward FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_idmax FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_mean FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_median FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FillNaTransformer_value FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/ Methods fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. FixSkewness FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/ Methods fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered. MeanCenterer MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause Methods fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered. OneHotEncoder OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/ Methods fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder. ReplaceMulticlass ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. ReplaceTransformer ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced. minmax_scaling minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"Mlearner.preprocessing"},{"location":"api_subpackages/mlearner.preprocessing/#dataanalyst","text":"DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/","title":"DataAnalyst"},{"location":"api_subpackages/mlearner.preprocessing/#methods","text":"boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#datacleaner","text":"DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/","title":"DataCleaner"},{"location":"api_subpackages/mlearner.preprocessing/#methods_1","text":"categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#dropoutliers","text":"DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/","title":"DropOutliers"},{"location":"api_subpackages/mlearner.preprocessing/#methods_2","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#extractcategories","text":"ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ExtractCategories"},{"location":"api_subpackages/mlearner.preprocessing/#methods_3","text":"fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#featuredropper","text":"FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/","title":"FeatureDropper"},{"location":"api_subpackages/mlearner.preprocessing/#methods_4","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_all","text":"FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/","title":"FillNaTransformer_all"},{"location":"api_subpackages/mlearner.preprocessing/#methods_5","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_any","text":"FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/","title":"FillNaTransformer_any"},{"location":"api_subpackages/mlearner.preprocessing/#methods_6","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_backward","text":"FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/","title":"FillNaTransformer_backward"},{"location":"api_subpackages/mlearner.preprocessing/#methods_7","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_forward","text":"FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/","title":"FillNaTransformer_forward"},{"location":"api_subpackages/mlearner.preprocessing/#methods_8","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_idmax","text":"FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/","title":"FillNaTransformer_idmax"},{"location":"api_subpackages/mlearner.preprocessing/#methods_9","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_mean","text":"FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/","title":"FillNaTransformer_mean"},{"location":"api_subpackages/mlearner.preprocessing/#methods_10","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_median","text":"FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/","title":"FillNaTransformer_median"},{"location":"api_subpackages/mlearner.preprocessing/#methods_11","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fillnatransformer_value","text":"FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/","title":"FillNaTransformer_value"},{"location":"api_subpackages/mlearner.preprocessing/#methods_12","text":"fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#fixskewness","text":"FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/","title":"FixSkewness"},{"location":"api_subpackages/mlearner.preprocessing/#methods_13","text":"fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#meancenterer","text":"MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause","title":"MeanCenterer"},{"location":"api_subpackages/mlearner.preprocessing/#methods_14","text":"fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#onehotencoder","text":"OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/","title":"OneHotEncoder"},{"location":"api_subpackages/mlearner.preprocessing/#methods_15","text":"fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#replacemulticlass","text":"ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/","title":"ReplaceMulticlass"},{"location":"api_subpackages/mlearner.preprocessing/#methods_16","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#replacetransformer","text":"ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ReplaceTransformer"},{"location":"api_subpackages/mlearner.preprocessing/#methods_17","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"api_subpackages/mlearner.preprocessing/#minmax_scaling","text":"minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"minmax_scaling"},{"location":"user_guide/data/create_dataset/","text":"create_dataset create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/","title":"Create dataset"},{"location":"user_guide/data/create_dataset/#create_dataset","text":"create_dataset(config, n) Generate a Dataset. Attributes config : dict Dictionary for dataset configuration: p.e.: dict = { - `'A'` : data_uniform(0, 1, n), - `'B'` : data_normal(n), - `'C'` : data_normal(mu=5, sd=2, n=n), - `'D'` : data_gamma(a=5, n=n) } n : int number of data in the dataset. Returns data : Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/create_dataset/","title":"create_dataset"},{"location":"user_guide/data/data_gamma/","text":"data_gamma data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/","title":"Data gamma"},{"location":"user_guide/data/data_gamma/#data_gamma","text":"data_gamma(a=5, n=100) Generate a Gamma data distribution. Attributes a : int or float Parameter form. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_gamma/","title":"data_gamma"},{"location":"user_guide/data/data_normal/","text":"data_normal data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/","title":"Data normal"},{"location":"user_guide/data/data_normal/#data_normal","text":"data_normal(mu=0, sd=1, n=100) Generate a Normal data distribution. Attributes mu : int or float mean value. sd : int or float standard deviation. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_normal/","title":"data_normal"},{"location":"user_guide/data/data_uniform/","text":"data_uniform data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/","title":"Data uniform"},{"location":"user_guide/data/data_uniform/#data_uniform","text":"data_uniform(a, b, n) Generate a Uniform data distribution. Attributes a : int or float manimum value of the entire dataset. b : int or float maximum value of the entire dataset. n : int number of data in the dataset. Returns data : Uniform data distribution. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/data_uniform/","title":"data_uniform"},{"location":"user_guide/data/wine_data/","text":"wine_data wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data","title":"Wine data"},{"location":"user_guide/data/wine_data/#wine_data","text":"wine_data() Wine dataset. Source: https://archive.ics.uci.edu/ml/datasets/Wine Number of samples: 178 Class labels: {0, 1, 2}, distribution: [59, 71, 48] Data Set Information: These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it) 1) Alcohol 2) Malic acid 3) Ash 4) Alcalinity of ash 5) Magnesium 6) Total phenols 7) Flavanoids 8) Nonflavanoid phenols 9) Proanthocyanins 10) Color intensity 11) Hue 12) OD280/OD315 of diluted wines 13) Proline In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging. Returns X, y : [n_samples, n_features], [n_class_labels] X is the feature matrix with 178 wine samples as rows and 13 feature columns. y is a 1-dimensional array of the 3 class labels 0, 1, 2 Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/data/wine_data","title":"wine_data"},{"location":"user_guide/load/DataLoad/","text":"DataLoad DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ Methods load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: 'str, path object or file-like object' Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: 'str' Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: 'str, default None' Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"DataLoad"},{"location":"user_guide/load/DataLoad/#dataload","text":"DataLoad(data) Loading a dataset from a file or dataframe. Parameters data: pandas [n_columns, n_features]. pandas Dataframe. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/","title":"DataLoad"},{"location":"user_guide/load/DataLoad/#methods","text":"load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: 'str, path object or file-like object' Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: 'str' Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: 'str, default None' Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None","title":"Methods"},{"location":"user_guide/preprocessing/DataAnalyst/","text":"DataAnalyst DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/ Methods boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None","title":"DataAnalyst"},{"location":"user_guide/preprocessing/DataAnalyst/#dataanalyst","text":"DataAnalyst(data) Class for Preprocessed object for data analysis. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/","title":"DataAnalyst"},{"location":"user_guide/preprocessing/DataAnalyst/#methods","text":"boxplot(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un BoxPlot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. corr_matrix(features=None, display=True, save_image=False, path='/') matriz de covarianza: Un valor positivo para r indica una asociacion positiva Un valor negativo para r indica una asociacion negativa. Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta, la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal. dispersion_categoria(features=None, target=None, display=False, save_image=False, path='/') Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target. Inputs: - data: Datos generales del dataset. - features: categorias a analizar. distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2') None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None reset() None sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/') None sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl') None","title":"Methods"},{"location":"user_guide/preprocessing/DataCleaner/","text":"DataCleaner DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/ Methods categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe","title":"DataCleaner"},{"location":"user_guide/preprocessing/DataCleaner/#datacleaner","text":"DataCleaner(data) Class to preprocessed object for data cleaning. Attributes data: pd.DataFrame of Dataset Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/","title":"DataCleaner"},{"location":"user_guide/preprocessing/DataCleaner/#methods","text":"categorical_vs_numerical() None dtypes() retorno del tipo de datos por columna isNull() None load_data(filename, sep=';', decimal=',', params) Loading a dataset from a csv file. Parameters filename: str, path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv . If you want to pass in a path object, pandas accepts any os.PathLike. By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin open function) or StringIO. seps: str Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python's builtin sniffer tool, csv.Sniffer. delimiter: str, default None Alias for sep. Attributes n: lenght of dataset. start: start iterator. end: end iterator. num: current iterator. Returns data: Pandas DataFrame, [n_samples, n_classes] Dataframe from dataset. Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/ load_dataframe(data) None missing_values() Numero de valores vacios en el dataframe. not_type_object() Deteccion de de categorias con type \"object\" reset() None type_object() Deteccion de de categorias con type \"object\" view_features() Mostrar features del dataframe","title":"Methods"},{"location":"user_guide/preprocessing/DropOutliers/","text":"DropOutliers DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"DropOutliers"},{"location":"user_guide/preprocessing/DropOutliers/#dropoutliers","text":"DropOutliers(features=[], display=False) Drop Outliers from dataframe Attributes features: list or tuple list of features to drop outliers [n_columns] display: boolean` Show histogram with changes made. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/","title":"DropOutliers"},{"location":"user_guide/preprocessing/DropOutliers/#methods","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"user_guide/preprocessing/ExtractCategories/","text":"ExtractCategories ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ExtractCategories"},{"location":"user_guide/preprocessing/ExtractCategories/#extractcategories","text":"ExtractCategories(categories=None, target=None) This transformer filters the selected dataset categories. Attributes categories: list of categories that you want to keep. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ExtractCategories"},{"location":"user_guide/preprocessing/ExtractCategories/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make filters the selected dataset categories. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FeatureDropper/","text":"FeatureDropper FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/ Methods fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"FeatureDropper"},{"location":"user_guide/preprocessing/FeatureDropper/#featuredropper","text":"FeatureDropper(drop=[]) Column drop according to the selected feature. Attributes drop: list of features to drop [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/","title":"FeatureDropper"},{"location":"user_guide/preprocessing/FeatureDropper/#methods","text":"fit(X, y=None, fit_params) Gets the columns that not drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X, fit_params) Features drop. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns dropped.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_all/","text":"FillNaTransformer_all FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer all"},{"location":"user_guide/preprocessing/FillNaTransformer_all/#fillnatransformer_all","text":"FillNaTransformer_all() This transformer delete row that there is all NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/","title":"FillNaTransformer_all"},{"location":"user_guide/preprocessing/FillNaTransformer_all/#methods","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_any/","text":"FillNaTransformer_any FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/ Methods fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer any"},{"location":"user_guide/preprocessing/FillNaTransformer_any/#fillnatransformer_any","text":"FillNaTransformer_any() This transformer delete row that there is some NaN. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/","title":"FillNaTransformer_any"},{"location":"user_guide/preprocessing/FillNaTransformer_any/#methods","text":"fit(X, y=None, fit_params) Not implemented. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) This transformer delete row that there is some NaN Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_backward/","text":"FillNaTransformer_backward FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer backward"},{"location":"user_guide/preprocessing/FillNaTransformer_backward/#fillnatransformer_backward","text":"FillNaTransformer_backward(columns=None) This transformer handles missing values closer backward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/","title":"FillNaTransformer_backward"},{"location":"user_guide/preprocessing/FillNaTransformer_backward/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_forward/","text":"FillNaTransformer_forward FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer forward"},{"location":"user_guide/preprocessing/FillNaTransformer_forward/#fillnatransformer_forward","text":"FillNaTransformer_forward(columns=None) This transformer handles missing values closer forward. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/","title":"FillNaTransformer_forward"},{"location":"user_guide/preprocessing/FillNaTransformer_forward/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_idmax/","text":"FillNaTransformer_idmax FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer idmax"},{"location":"user_guide/preprocessing/FillNaTransformer_idmax/#fillnatransformer_idmax","text":"FillNaTransformer_idmax(columns=None) This transformer handles missing values for idmax. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/","title":"FillNaTransformer_idmax"},{"location":"user_guide/preprocessing/FillNaTransformer_idmax/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_mean/","text":"FillNaTransformer_mean FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer mean"},{"location":"user_guide/preprocessing/FillNaTransformer_mean/#fillnatransformer_mean","text":"FillNaTransformer_mean(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/","title":"FillNaTransformer_mean"},{"location":"user_guide/preprocessing/FillNaTransformer_mean/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_median/","text":"FillNaTransformer_median FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer median"},{"location":"user_guide/preprocessing/FillNaTransformer_median/#fillnatransformer_median","text":"FillNaTransformer_median(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/","title":"FillNaTransformer_median"},{"location":"user_guide/preprocessing/FillNaTransformer_median/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FillNaTransformer_value/","text":"FillNaTransformer_value FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/ Methods fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"FillNaTransformer value"},{"location":"user_guide/preprocessing/FillNaTransformer_value/#fillnatransformer_value","text":"FillNaTransformer_value(columns=None) This transformer handles missing values. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/","title":"FillNaTransformer_value"},{"location":"user_guide/preprocessing/FillNaTransformer_value/#methods","text":"fit(X, y=None, value=None, fit_params) Gets the columns to make a replace missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) this transformer handles missing values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/FixSkewness/","text":"FixSkewness FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/ Methods fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"FixSkewness"},{"location":"user_guide/preprocessing/FixSkewness/#fixskewness","text":"FixSkewness(columns=None) This transformer applies log to skewed features. Attributes columns: npandas [n_columns] Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/","title":"FixSkewness"},{"location":"user_guide/preprocessing/FixSkewness/#methods","text":"fit(X, y=None, fit_params) Selecting skewed columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"user_guide/preprocessing/MeanCenterer/","text":"MeanCenterer MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause Methods fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"MeanCenterer"},{"location":"user_guide/preprocessing/MeanCenterer/#meancenterer","text":"MeanCenterer() Column centering of pandas Dataframe. Attributes col_means: numpy.ndarray [n_columns] or pandas [n_columns] mean values for centering after fitting the MeanCenterer object. Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/ adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py Author: Sebastian Raschka License: BSD 3 clause","title":"MeanCenterer"},{"location":"user_guide/preprocessing/MeanCenterer/#methods","text":"fit(X, y=None) Gets the column means for mean centering. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Centers a pandas. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns centered.","title":"Methods"},{"location":"user_guide/preprocessing/OneHotEncoder/","text":"OneHotEncoder OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/ Methods fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder.","title":"OneHotEncoder"},{"location":"user_guide/preprocessing/OneHotEncoder/#onehotencoder","text":"OneHotEncoder(columns=None, numerical=[]) This transformer applies One-Hot-Encoder to features. Attributes numerical: pandas [n_columns]. numerical columns to be treated as categorical. columns: pandas [n_columns]. columns to use (if None then all categorical variables are included). Examples For usage examples, please see: https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/","title":"OneHotEncoder"},{"location":"user_guide/preprocessing/OneHotEncoder/#methods","text":"fit(X, y=None, fit_params) Selecting OneHotEncoder columns from the dataset. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Trransformer applies log to skewed features. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {DAtaframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns encoder.","title":"Methods"},{"location":"user_guide/preprocessing/ReplaceMulticlass/","text":"ReplaceMulticlass ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ReplaceMulticlass"},{"location":"user_guide/preprocessing/ReplaceMulticlass/#replacemulticlass","text":"ReplaceMulticlass(columns=None, mapping=None) This transformer replace some categorical values with others. Attributes columns: list of columns to transformer [n_columns] Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/","title":"ReplaceMulticlass"},{"location":"user_guide/preprocessing/ReplaceMulticlass/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace to categorical values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/ReplaceTransformer/","text":"ReplaceTransformer ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/ Methods fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"ReplaceTransformer"},{"location":"user_guide/preprocessing/ReplaceTransformer/#replacetransformer","text":"ReplaceTransformer(columns=None, mapping=None) This transformer replace some values with others. Attributes columns: list of columns to transformer [n_columns] mapping: dict`, for example: mapping = {\"yes\": 1, \"no\": 0} Examples For usage examples, please see https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/","title":"ReplaceTransformer"},{"location":"user_guide/preprocessing/ReplaceTransformer/#methods","text":"fit(X, y=None, fit_params) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe, where n_samples is the number of samples and n_features is the number of features. Returns self fit_transform(X, y=None, fit_params) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : numpy array of shape [n_samples, n_features] Training set. y : numpy array of shape [n_samples] Target values. Returns X_new : numpy array of shape [n_samples, n_features_new] Transformed array. get_params(deep=True) Get parameters for this estimator. Parameters deep : boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns params : mapping of string to any Parameter names mapped to their values. set_params( params) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Returns self transform(X) Gets the columns to make a replace values. Parameters X : {Dataframe}, shape = [n_samples, n_features] Dataframe of samples, where n_samples is the number of samples and n_features is the number of features. Returns X_transform : {Dataframe}, shape = [n_samples, n_features] A copy of the input Dataframe with the columns replaced.","title":"Methods"},{"location":"user_guide/preprocessing/minmax_scaling/","text":"minmax_scaling minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"Minmax scaling"},{"location":"user_guide/preprocessing/minmax_scaling/#minmax_scaling","text":"minmax_scaling(array, columns, min_val=0, max_val=1) In max scaling of pandas DataFrames. Parameters array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns]. columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...] min_val : int or float , optional (default= 0 ) minimum value after rescaling. max_val : int or float , optional (default= 1 ) maximum value after rescaling. Returns df_new : pandas DataFrame object. Copy of the array or DataFrame with rescaled columns. Examples For usage examples, please see [http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.) adapted from https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py Author: Sebastian Raschka <sebastianraschka.com> License: BSD 3 clause","title":"minmax_scaling"}]}