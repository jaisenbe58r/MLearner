<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A library consisting of useful tools and extensions for the day-to-day data science tasks."> 
    <meta name="author" content="Jaime Sendra Berenguer"> 
    <link rel="canonical" href="https://jaisenbe58r.github.io/MLearner/api_subpackages/mlearner.preprocessing/">
    <link rel="shortcut icon" href="../../img/favicon.ico">

    <title>Mlearner.preprocessing - mlearner</title>

    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/base.css" rel="stylesheet">
    <link href="../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">


    <link href="../../cinder/css/base.css" rel="stylesheet">


    <link href="../../cinder/css/bootstrap-custom.css" rel="stylesheet">


    <link href="../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">


    <link href="../../cinder/css/cinder.css" rel="stylesheet">


    <link href="../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">


    <link href="../../cinder/css/highlight.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-163860068-1', 'jaisenbe58r.github.io/MLearner/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="../..">mlearner</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../USER_GUIDE_INDEX/">User Guide Index</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">load</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/load/DataLoad/">DataLoad</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/data/wine_data/">Wine data</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/data_normal/">Data normal</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/data_gamma/">Data gamma</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/data_uniform/">Data uniform</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/create_dataset/">Create dataset</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FeatureDropper/">FeatureDropper</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_median/">FillNaTransformer median</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_mean/">FillNaTransformer mean</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_idmax/">FillNaTransformer idmax</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_any/">FillNaTransformer any</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_all/">FillNaTransformer all</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_value/">FillNaTransformer value</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_backward/">FillNaTransformer backward</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FillNaTransformer_forward/">FillNaTransformer forward</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/FixSkewness/">FixSkewness</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/OneHotEncoder/">OneHotEncoder</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/DropOutliers/">DropOutliers</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/ExtractCategories/">ExtractCategories</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/ReplaceMulticlass/">ReplaceMulticlass</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/ReplaceTransformer/">ReplaceTransformer</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/DataCleaner/">DataCleaner</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/DataAnalyst/">Preprocessing</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature selections</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/feature_selections/FeatureSelection/">FeatureSelection</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">models</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/models/modelXGBoost/">modelXGBoost</a>
</li>

        
            
<li >
    <a href="../../user_guide/models/modelLightBoost/">modelLightBoost</a>
</li>

        
            
<li >
    <a href="../../user_guide/models/modelCatBoost/">modelCatBoost</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">clasifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/clasifier/PipelineClasificators/">PipelineClasificators</a>
</li>

        
            
<li >
    <a href="../../user_guide/clasifier/TrainingUtilities/">TrainingUtilities</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">training</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/training/Training/">Training</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluation</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/evaluation/EvaluationModels">None</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/utils/ParamsManager/">ParamsManager</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../mlearner.data/">Mlearner.data</a>
</li>

                        
                            
<li class="active">
    <a href="./">Mlearner.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../mlearner.externals.md">None</a>
</li>

                        
                            
<li >
    <a href="../mlearner.load/">Mlearner.load</a>
</li>

                        
                            
<li >
    <a href="../mlearner.classifier/">Mlearner.classifier</a>
</li>

                        
                            
<li >
    <a href="../mlearner.feature_selection/">Mlearner.feature selection</a>
</li>

                        
                            
<li >
    <a href="../mlearner.models/">Mlearner.models</a>
</li>

                        
                            
<li >
    <a href="../mlearner.training/">Mlearner.training</a>
</li>

                        
                            
<li >
    <a href="../mlearner.utils/">Mlearner.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../CHANGELOG/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../CONTRIBUTING/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../cite/">Citing mlearner</a>
</li>

                        
                            
<li >
    <a href="../../discuss/">Discuss</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>

                <!--
                    <li >
                        <a rel="next" href="../mlearner.data/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../mlearner.load/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>-->
                    <li>
                        <a href="https://github.com/jaisenbe58r/MLearner"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#categoricalencoder">CategoricalEncoder</a></li>
            <li class="second-level"><a href="#methods">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#copyfeatures">CopyFeatures</a></li>
            <li class="second-level"><a href="#methods_1">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#dataanalyst">DataAnalyst</a></li>
            <li class="second-level"><a href="#methods_2">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#datacleaner">DataCleaner</a></li>
            <li class="second-level"><a href="#methods_3">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#dataexploratory">DataExploratory</a></li>
            <li class="second-level"><a href="#methods_4">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#dataframeselector">DataFrameSelector</a></li>
            <li class="second-level"><a href="#methods_5">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#dropfeatures">DropFeatures</a></li>
            <li class="second-level"><a href="#methods_6">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#dropoutliers">DropOutliers</a></li>
            <li class="second-level"><a href="#methods_7">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#extractcategories">ExtractCategories</a></li>
            <li class="second-level"><a href="#methods_8">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#featuredropper">FeatureDropper</a></li>
            <li class="second-level"><a href="#methods_9">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#featureselector">FeatureSelector</a></li>
            <li class="second-level"><a href="#methods_10">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_all">FillNaTransformer_all</a></li>
            <li class="second-level"><a href="#methods_11">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_any">FillNaTransformer_any</a></li>
            <li class="second-level"><a href="#methods_12">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_backward">FillNaTransformer_backward</a></li>
            <li class="second-level"><a href="#methods_13">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_forward">FillNaTransformer_forward</a></li>
            <li class="second-level"><a href="#methods_14">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_idmax">FillNaTransformer_idmax</a></li>
            <li class="second-level"><a href="#methods_15">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_mean">FillNaTransformer_mean</a></li>
            <li class="second-level"><a href="#methods_16">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_median">FillNaTransformer_median</a></li>
            <li class="second-level"><a href="#methods_17">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fillnatransformer_value">FillNaTransformer_value</a></li>
            <li class="second-level"><a href="#methods_18">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#fixskewness">FixSkewness</a></li>
            <li class="second-level"><a href="#methods_19">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#lda_add">LDA_add</a></li>
            <li class="second-level"><a href="#methods_20">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#lda_selector">LDA_selector</a></li>
            <li class="second-level"><a href="#methods_21">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#labelencoder">LabelEncoder</a></li>
            <li class="second-level"><a href="#methods_22">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#meancenterer">MeanCenterer</a></li>
            <li class="second-level"><a href="#methods_23">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#onehotencoder">OneHotEncoder</a></li>
            <li class="second-level"><a href="#methods_24">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#pca_add">PCA_add</a></li>
            <li class="second-level"><a href="#methods_25">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#pca_selector">PCA_selector</a></li>
            <li class="second-level"><a href="#methods_26">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#replacemulticlass">ReplaceMulticlass</a></li>
            <li class="second-level"><a href="#methods_27">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#replacetransformer">ReplaceTransformer</a></li>
            <li class="second-level"><a href="#methods_28">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#standardscaler">StandardScaler</a></li>
            <li class="second-level"><a href="#methods_29">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#minmax_scaling">minmax_scaling</a></li>
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<p>mlearner version: 0.1.3dev0 </p>
<h2 id="categoricalencoder">CategoricalEncoder</h2>
<p><em>CategoricalEncoder(encoding='onehot', categories='auto', dtype=<class 'numpy.float64'>, handle_unknown='error')</em></p>
<p>Encode categorical features as a numeric array.
The input to this transformer should be a matrix of integers or strings,
denoting the values taken on by categorical (discrete) features.
The features can be encoded using a one-hot aka one-of-K scheme
(<code>encoding='onehot'</code>, the default) or converted to ordinal integers
(<code>encoding='ordinal'</code>).
This encoding is needed for feeding categorical data to many scikit-learn
estimators, notably linear models and SVMs with the standard kernels.
Read more in the :ref:<code>User Guide &lt;preprocessing_categorical_features&gt;</code>.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>encoding</code> : str, 'onehot', 'onehot-dense' or 'ordinal'</p>
<p>The type of encoding to use (default is 'onehot'):
- 'onehot': encode the features using a one-hot aka one-of-K scheme
(or also called 'dummy' encoding). This creates a binary column for
each category and returns a sparse matrix.
- 'onehot-dense': the same as 'onehot' but returns a dense array
instead of a sparse matrix.
- 'ordinal': encode the features as ordinal integers. This results in
a single column of integers (0 to n_categories - 1) per feature.</p>
</li>
<li>
<p><code>categories</code> : 'auto' or a list of lists/arrays of values.</p>
<p>Categories (unique values) per feature:</p>
</li>
<li>
<p><code>- 'auto'</code> : Determine categories automatically from the training data.</p>
</li>
<li>
<p><code>- list</code> : <code>categories[i]</code> holds the categories expected in the ith</p>
<p>column. The passed categories are sorted before encoding the data
(used categories can be found in the <code>categories_</code> attribute).</p>
</li>
<li>
<p><code>dtype</code> : number type, default np.float64</p>
<p>Desired dtype of output.</p>
</li>
<li>
<p><code>handle_unknown</code> : 'error' (default) or 'ignore'</p>
<p>Whether to raise an error or ignore if a unknown categorical feature is
present during transform (default is to raise). When this is parameter
is set to 'ignore' and an unknown category is encountered during
transform, the resulting one-hot encoded columns for this feature
will be all zeros.
Ignoring unknown categories is not supported for
<code>encoding='ordinal'</code>.</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>categories_</code> : list of arrays</p>
<p>The categories of each feature determined during fitting. When
categories were specified manually, this holds the sorted categories
(in order corresponding with output of <code>transform</code>).</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>Given a dataset with three features and two samples, we let the encoder
    find the maximum value per feature and transform the data to a binary
    one-hot encoding.
    &gt;&gt;&gt; from sklearn.preprocessing import CategoricalEncoder
    &gt;&gt;&gt; enc = CategoricalEncoder(handle_unknown='ignore')
    &gt;&gt;&gt; enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])
    ... # doctest: +ELLIPSIS
    CategoricalEncoder(categories='auto', dtype=&lt;... 'numpy.float64'&gt;,
    encoding='onehot', handle_unknown='ignore')
    &gt;&gt;&gt; enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()
    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],
    [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])</p>
<p><strong>See also</strong></p>
<ul>
<li>
<p><code>sklearn.preprocessing.OneHotEncoder</code> : performs a one-hot encoding of</p>
<p>integer ordinal features. The <code>OneHotEncoder assumes</code> that input
features take on values in the range <code>[0, max(feature)]</code> instead of
using the unique values.</p>
</li>
<li>
<p><code>sklearn.feature_extraction.DictVectorizer</code> : performs a one-hot encoding of</p>
<p>dictionary items (also handles string-valued features).</p>
</li>
<li>
<p><code>sklearn.feature_extraction.FeatureHasher</code> : performs an approximate one-hot</p>
<p>encoding of dictionary items or strings.</p>
</li>
</ul>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Fit the CategoricalEncoder to X.
<strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape [n_samples, n_feature]</p>
<p>The data to determine the categories of each feature.
<strong>Returns</strong></p>
</li>
</ul>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Transform X using one-hot encoding.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape [n_samples, n_features]</p>
<p>The data to encode.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_out</code> : sparse matrix or a 2-d array</p>
<p>Transformed input.</p>
</li>
</ul>
<h2 id="copyfeatures">CopyFeatures</h2>
<p><em>CopyFeatures(columns=None, prefix='')</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_1">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>None</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>None</p>
<h2 id="dataanalyst">DataAnalyst</h2>
<p><em>DataAnalyst(data)</em></p>
<p>Class for Preprocessed object for data analysis.</p>
<p><strong>Attributes</strong></p>
<p>data: pd.DataFrame of Dataset</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataAnalyst/</p>
<h3 id="methods_2">Methods</h3>
<hr>

<p><em>Xy_dataset(target=None)</em></p>
<p>Separar datos del target en conjunto (X, y)</p>
<hr>

<p><em>boxplot(features=None, target=None, display=False, save_image=False, path='/')</em></p>
<p>Funcion que realiza un BoxPlot sobre la dispesion de cada categoria
respecto a los grupos de target.</p>
<p>Inputs:
- data: Datos generales del dataset.
- features: categorias a analizar.</p>
<hr>

<p><em>categorical_vs_numerical()</em></p>
<p>None</p>
<hr>

<p><em>corr_matrix(features=None, display=True, save_image=False, path='/')</em></p>
<p>matriz de covarianza:</p>
<p>Un valor positivo para r indica una asociacion positiva
Un valor negativo para r indica una asociacion negativa.</p>
<p>Cuanto mas cerca estar de 1cuanto mas se acercan los puntos de datos a una linea recta,
la asociacion lineal es mas fuerte. Cuanto mas cerca este r de 0, lo que debilita la asociacion lineal.</p>
<hr>

<p><em>dispersion_categoria(features=None, target=None, density=True, display=False, save_image=False, path='/')</em></p>
<p>Funcion que realiza un plot sobre la dispesion de cada categoria respecto a los grupos de target.</p>
<p>Inputs:
- data: Datos generales del dataset.
- features: categorias a analizar.</p>
<hr>

<p><em>distribution_targets(target=None, display=True, save_image=False, path='/', palette='Set2')</em></p>
<p>None</p>
<hr>

<p><em>dtypes(X=None)</em></p>
<p>retorno del tipo de datos por columna</p>
<hr>

<p><em>isNull()</em></p>
<p>None</p>
<hr>

<p><em>load_data(filename, sep=';', decimal=',', </em><em>params)</em></p>
<p>Loading a dataset from a csv file.</p>
<p><strong>Parameters</strong></p>
<p>filename: <code>str, path object or file-like object</code>
Any valid string path is acceptable. The string could be a URL.
Valid URL schemes include http, ftp, s3, and file. For file URLs,
a host is expected. A local file could be:
<code>file://localhost/path/to/table.csv</code>.
If you want to pass in a path object, pandas accepts any os.PathLike.
By file-like object, we refer to objects with a read() method,
such as a file handler (e.g. via builtin open function) or StringIO.</p>
<p>seps: <code>str</code>
Delimiter to use. If sep is None, the C engine cannot automatically
detect the separator, but the Python parsing engine can, meaning the
latter will be used and automatically detect the separator by Python's
builtin sniffer tool, csv.Sniffer.</p>
<p>delimiter: <code>str, default None</code>
Alias for sep.</p>
<p><strong>Attributes</strong></p>
<p>n: lenght of dataset.
start: start iterator.
end: end iterator.
num: current iterator.</p>
<p><strong>Returns</strong></p>
<p>data: Pandas DataFrame, [n_samples, n_classes]
Dataframe from dataset.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see:
https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/</p>
<hr>

<p><em>load_dataframe(data)</em></p>
<p>None</p>
<hr>

<p><em>missing_values(X=None)</em></p>
<p>Numero de valores vacios en el dataframe.</p>
<hr>

<p><em>not_type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>reset()</em></p>
<p>None</p>
<hr>

<p><em>sns_jointplot(feature1, feature2, target=None, categoria1=None, categoria2=None, display=True, save_image=False, path='/')</em></p>
<p>None</p>
<hr>

<p><em>sns_pairplot(features=None, target=None, display=True, save_image=False, path='/', palette='husl')</em></p>
<p>None</p>
<hr>

<p><em>type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>view_features()</em></p>
<p>Mostrar features del dataframe</p>
<h2 id="datacleaner">DataCleaner</h2>
<p><em>DataCleaner(data)</em></p>
<p>Class to preprocessed object for data cleaning.</p>
<p><strong>Attributes</strong></p>
<p>data: <code>pd.DataFrame</code> of Dataset</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/</p>
<h3 id="methods_3">Methods</h3>
<hr>

<p><em>categorical_vs_numerical()</em></p>
<p>None</p>
<hr>

<p><em>dtypes()</em></p>
<p>retorno del tipo de datos por columna</p>
<hr>

<p><em>isNull()</em></p>
<p>None</p>
<hr>

<p><em>load_data(filename, sep=';', decimal=',', </em><em>params)</em></p>
<p>Loading a dataset from a csv file.</p>
<p><strong>Parameters</strong></p>
<p>filename: <code>str, path object or file-like object</code>
Any valid string path is acceptable. The string could be a URL.
Valid URL schemes include http, ftp, s3, and file. For file URLs,
a host is expected. A local file could be:
<code>file://localhost/path/to/table.csv</code>.
If you want to pass in a path object, pandas accepts any os.PathLike.
By file-like object, we refer to objects with a read() method,
such as a file handler (e.g. via builtin open function) or StringIO.</p>
<p>seps: <code>str</code>
Delimiter to use. If sep is None, the C engine cannot automatically
detect the separator, but the Python parsing engine can, meaning the
latter will be used and automatically detect the separator by Python's
builtin sniffer tool, csv.Sniffer.</p>
<p>delimiter: <code>str, default None</code>
Alias for sep.</p>
<p><strong>Attributes</strong></p>
<p>n: lenght of dataset.
start: start iterator.
end: end iterator.
num: current iterator.</p>
<p><strong>Returns</strong></p>
<p>data: Pandas DataFrame, [n_samples, n_classes]
Dataframe from dataset.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see:
https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/</p>
<hr>

<p><em>load_dataframe(data)</em></p>
<p>None</p>
<hr>

<p><em>missing_values()</em></p>
<p>Numero de valores vacios en el dataframe.</p>
<hr>

<p><em>not_type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>reset()</em></p>
<p>None</p>
<hr>

<p><em>type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>view_features()</em></p>
<p>Mostrar features del dataframe</p>
<h2 id="dataexploratory">DataExploratory</h2>
<p><em>DataExploratory(data)</em></p>
<p>Class to preprocessed object for data cleaning.</p>
<p><strong>Attributes</strong></p>
<p>data: <code>pd.DataFrame</code> of Dataset</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DataCleaner/</p>
<h3 id="methods_4">Methods</h3>
<hr>

<p><em>categorical_vs_numerical()</em></p>
<p>None</p>
<hr>

<p><em>dtypes(X=None)</em></p>
<p>retorno del tipo de datos por columna</p>
<hr>

<p><em>isNull()</em></p>
<p>None</p>
<hr>

<p><em>load_data(filename, sep=';', decimal=',', </em><em>params)</em></p>
<p>Loading a dataset from a csv file.</p>
<p><strong>Parameters</strong></p>
<p>filename: <code>str, path object or file-like object</code>
Any valid string path is acceptable. The string could be a URL.
Valid URL schemes include http, ftp, s3, and file. For file URLs,
a host is expected. A local file could be:
<code>file://localhost/path/to/table.csv</code>.
If you want to pass in a path object, pandas accepts any os.PathLike.
By file-like object, we refer to objects with a read() method,
such as a file handler (e.g. via builtin open function) or StringIO.</p>
<p>seps: <code>str</code>
Delimiter to use. If sep is None, the C engine cannot automatically
detect the separator, but the Python parsing engine can, meaning the
latter will be used and automatically detect the separator by Python's
builtin sniffer tool, csv.Sniffer.</p>
<p>delimiter: <code>str, default None</code>
Alias for sep.</p>
<p><strong>Attributes</strong></p>
<p>n: lenght of dataset.
start: start iterator.
end: end iterator.
num: current iterator.</p>
<p><strong>Returns</strong></p>
<p>data: Pandas DataFrame, [n_samples, n_classes]
Dataframe from dataset.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see:
https://jaisenbe58r.github.io/MLearner/user_guide/load/DataLoad/</p>
<hr>

<p><em>load_dataframe(data)</em></p>
<p>None</p>
<hr>

<p><em>missing_values(X=None)</em></p>
<p>Numero de valores vacios en el dataframe.</p>
<hr>

<p><em>not_type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>reset()</em></p>
<p>None</p>
<hr>

<p><em>type_object()</em></p>
<p>Deteccion de de categorias con type "object"</p>
<hr>

<p><em>view_features()</em></p>
<p>Mostrar features del dataframe</p>
<h2 id="dataframeselector">DataFrameSelector</h2>
<p><em>DataFrameSelector(attribute_names)</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_5">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>None</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>None</p>
<h2 id="dropfeatures">DropFeatures</h2>
<p><em>DropFeatures(columns_drop=None, random_state=99)</em></p>
<p>This transformer drop features.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropFeatures/</p>
<h3 id="methods_6">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="dropoutliers">DropOutliers</h2>
<p><em>DropOutliers(features=[], display=False)</em></p>
<p>Drop Outliers from dataframe</p>
<p><strong>Attributes</strong></p>
<p>features: <code>list</code>or <code>tuple
list of features to drop outliers [n_columns]
display:</code>boolean`
Show histogram with changes made.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/DropOutliers/</p>
<h3 id="methods_7">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns that not drop.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X, </em><em>fit_params)</em></p>
<p>Features drop.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns dropped.</p>
</li>
</ul>
<h2 id="extractcategories">ExtractCategories</h2>
<p><em>ExtractCategories(categories=None, target=None)</em></p>
<p>This transformer filters the selected dataset categories.</p>
<p><strong>Attributes</strong></p>
<p>categories: <code>list</code> of categories that you want to keep.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/</p>
<h3 id="methods_8">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make filters the selected dataset categories.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Gets the columns to make filters the selected dataset categories.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="featuredropper">FeatureDropper</h2>
<p><em>FeatureDropper(drop=[])</em></p>
<p>Column drop according to the selected feature.</p>
<p><strong>Attributes</strong></p>
<p>drop: list of features to drop [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureDropper/</p>
<h3 id="methods_9">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns that not drop.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X, </em><em>fit_params)</em></p>
<p>Features drop.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns dropped.</p>
</li>
</ul>
<h2 id="featureselector">FeatureSelector</h2>
<p><em>FeatureSelector(columns=None, random_state=99)</em></p>
<p>This transformer select features.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FeatureSelector/</p>
<h3 id="methods_10">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_all">FillNaTransformer_all</h2>
<p><em>FillNaTransformer_all()</em></p>
<p>This transformer delete row that there is all NaN.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_all/</p>
<h3 id="methods_11">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Not implemented.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>This transformer delete row that there is some NaN</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_any">FillNaTransformer_any</h2>
<p><em>FillNaTransformer_any()</em></p>
<p>This transformer delete row that there is some NaN.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_any/</p>
<h3 id="methods_12">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Not implemented.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>This transformer delete row that there is some NaN</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_backward">FillNaTransformer_backward</h2>
<p><em>FillNaTransformer_backward(columns=None)</em></p>
<p>This transformer handles missing values closer backward.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_backward/</p>
<h3 id="methods_13">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_forward">FillNaTransformer_forward</h2>
<p><em>FillNaTransformer_forward(columns=None)</em></p>
<p>This transformer handles missing values closer forward.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_forward/</p>
<h3 id="methods_14">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_idmax">FillNaTransformer_idmax</h2>
<p><em>FillNaTransformer_idmax(columns=None)</em></p>
<p>This transformer handles missing values for idmax.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_idmax/</p>
<h3 id="methods_15">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_mean">FillNaTransformer_mean</h2>
<p><em>FillNaTransformer_mean(columns=None)</em></p>
<p>This transformer handles missing values.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_mean/</p>
<h3 id="methods_16">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_median">FillNaTransformer_median</h2>
<p><em>FillNaTransformer_median(columns=None)</em></p>
<p>This transformer handles missing values.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_median/</p>
<h3 id="methods_17">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fillnatransformer_value">FillNaTransformer_value</h2>
<p><em>FillNaTransformer_value(columns=None)</em></p>
<p>This transformer handles missing values.</p>
<p><strong>Attributes</strong></p>
<p>columns: list of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FillNaTransformer_value/</p>
<h3 id="methods_18">Methods</h3>
<hr>

<p><em>fit(X, y=None, value=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>this transformer handles missing values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="fixskewness">FixSkewness</h2>
<p><em>FixSkewness(columns=None, drop=True)</em></p>
<p>This transformer applies log to skewed features.</p>
<p><strong>Attributes</strong></p>
<p>columns:  npandas [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see:
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/FixSkewness/</p>
<h3 id="methods_19">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Selecting skewed columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies log to skewed features.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="lda_add">LDA_add</h2>
<p><em>LDA_add(columns=None, LDA_name=None, random_state=99)</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_20">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Selecting LDA columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies LDA.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="lda_selector">LDA_selector</h2>
<p><em>LDA_selector(columns=None, random_state=99)</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_21">Methods</h3>
<hr>

<p><em>fit(X, y)</em></p>
<p>Selecting LDA columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies LDA.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="labelencoder">LabelEncoder</h2>
<p><em>LabelEncoder()</em></p>
<p>Encode target labels with value between 0 and n_classes-1.</p>
<p>This transformer should be used to encode target values, <em>i.e.</em> <code>y</code>, and
not the input <code>X</code>.</p>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_targets&gt;</code>.</p>
<p>.. versionadded:: 0.12</p>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>classes_</code> : array of shape (n_class,)</p>
<p>Holds the label for each class.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p><code>LabelEncoder</code> can be used to normalize labels.</p>
<pre><code>&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; le = preprocessing.LabelEncoder()
&gt;&gt;&gt; le.fit([1, 2, 2, 6])
LabelEncoder()
&gt;&gt;&gt; le.classes_
array([1, 2, 6])
&gt;&gt;&gt; le.transform([1, 1, 2, 6])
array([0, 0, 1, 2]...)
&gt;&gt;&gt; le.inverse_transform([0, 0, 1, 2])
array([1, 1, 2, 6])

It can also be used to transform non-numerical labels (as long as they are
hashable and comparable) to numerical labels.

&gt;&gt;&gt; le = preprocessing.LabelEncoder()
&gt;&gt;&gt; le.fit(["paris", "paris", "tokyo", "amsterdam"])
LabelEncoder()
&gt;&gt;&gt; list(le.classes_)
['amsterdam', 'paris', 'tokyo']
&gt;&gt;&gt; le.transform(["tokyo", "tokyo", "paris"])
array([2, 2, 1]...)
&gt;&gt;&gt; list(le.inverse_transform([2, 2, 1]))
['tokyo', 'tokyo', 'paris']
</code></pre>
<p><strong>See also</strong></p>
<ul>
<li>
<p><code>sklearn.preprocessing.OrdinalEncoder</code> : Encode categorical features</p>
<p>using an ordinal encoding scheme.</p>
</li>
<li>
<p><code>sklearn.preprocessing.OneHotEncoder</code> : Encode categorical features</p>
<p>as a one-hot numeric array.</p>
</li>
</ul>
<h3 id="methods_22">Methods</h3>
<hr>

<p><em>fit(y)</em></p>
<p>Fit label encoder</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y</code> : array-like of shape (n_samples,)</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : returns an instance of self.</li>
</ul>
<hr>

<p><em>fit_transform(y)</em></p>
<p>Fit label encoder and return encoded labels</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y</code> : array-like of shape [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>y</code> : array-like of shape [n_samples]</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>inverse_transform(y)</em></p>
<p>Transform labels back to original encoding.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>y</code> : numpy array of shape [n_samples]</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(y)</em></p>
<p>Transform labels to normalized encoding.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y</code> : array-like of shape [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>y</code> : array-like of shape [n_samples]</li>
</ul>
<h2 id="meancenterer">MeanCenterer</h2>
<p><em>MeanCenterer(columns=None)</em></p>
<p>Column centering of pandas Dataframe.</p>
<p><strong>Attributes</strong></p>
<p>col_means:  numpy.ndarray [n_columns] or pandas [n_columns]
mean values for centering after fitting the MeanCenterer object.</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/MeanCenterer/</p>
<p>adapted from
https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/mean_centering.py
Author: Sebastian Raschka <sebastianraschka.com>
License: BSD 3 clause</p>
<h3 id="methods_23">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Gets the column means for mean centering.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Centers a pandas.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="onehotencoder">OneHotEncoder</h2>
<p><em>OneHotEncoder(columns=None, numerical=[], Drop=True)</em></p>
<p>This transformer applies One-Hot-Encoder to features.</p>
<p><strong>Attributes</strong></p>
<p>numerical: pandas [n_columns].
numerical columns to be treated as categorical.
columns:  pandas [n_columns].
columns to use (if None then all categorical variables are included).</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see:
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/OneHotEncoder/</p>
<h3 id="methods_24">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Selecting OneHotEncoder columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies log to skewed features.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns encoder.</p>
</li>
</ul>
<h2 id="pca_add">PCA_add</h2>
<p><em>PCA_add(columns=None, n_components=2, PCA_name=None, random_state=99)</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_25">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Selecting PCA columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies PCA.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="pca_selector">PCA_selector</h2>
<p><em>PCA_selector(columns=None, n_components=2, random_state=99)</em></p>
<p>Base class for all estimators in scikit-learn</p>
<p><strong>Notes</strong></p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h3 id="methods_26">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Selecting PCA columns from the dataset.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Trransformer applies PCA.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {DAtaframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns centered.</p>
</li>
</ul>
<h2 id="replacemulticlass">ReplaceMulticlass</h2>
<p><em>ReplaceMulticlass(columns=None)</em></p>
<p>This transformer replace some categorical values with others.</p>
<p><strong>Attributes</strong></p>
<p>columns: <code>list</code> of columns to transformer [n_columns]</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceMulticlass/</p>
<h3 id="methods_27">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Gets the columns to make a replace to categorical values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="replacetransformer">ReplaceTransformer</h2>
<p><em>ReplaceTransformer(columns=None, mapping=None)</em></p>
<p>This transformer replace some values with others.</p>
<p><strong>Attributes</strong></p>
<p>columns: <code>list</code> of columns to transformer [n_columns]</p>
<p>mapping: dict`, for example:</p>
<pre><code>mapping = {&quot;yes&quot;: 1, &quot;no&quot;: 0}
</code></pre>

<p><strong>Examples</strong></p>
<p>For usage examples, please see
https://jaisenbe58r.github.io/MLearner/user_guide/preprocessing/ReplaceTransformer/</p>
<h3 id="methods_28">Methods</h3>
<hr>

<p><em>fit(X, y=None, </em><em>fit_params)</em></p>
<p>Gets the columns to make a replace values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Gets the columns to make a replace values.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>Dataframe of samples, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_transform</code> : {Dataframe}, shape = [n_samples, n_features]</p>
<p>A copy of the input Dataframe with the columns replaced.</p>
</li>
</ul>
<h2 id="standardscaler">StandardScaler</h2>
<p><em>StandardScaler(copy=True, with_mean=True, with_std=True)</em></p>
<p>Standardize features by removing the mean and scaling to unit variance</p>
<p>The standard score of a sample <code>x</code> is calculated as:</p>
<p>z = (x - u) / s</p>
<p>where <code>u</code> is the mean of the training samples or zero if <code>with_mean=False</code>,
and <code>s</code> is the standard deviation of the training samples or one if
<code>with_std=False</code>.</p>
<p>Centering and scaling happen independently on each feature by computing
the relevant statistics on the samples in the training set. Mean and
standard deviation are then stored to be used on later data using
:meth:<code>transform</code>.</p>
<p>Standardization of a dataset is a common requirement for many
machine learning estimators: they might behave badly if the
individual features do not more or less look like standard normally
distributed data (e.g. Gaussian with 0 mean and unit variance).</p>
<p>For instance many elements used in the objective function of
a learning algorithm (such as the RBF kernel of Support Vector
Machines or the L1 and L2 regularizers of linear models) assume that
all features are centered around 0 and have variance in the same
order. If a feature has a variance that is orders of magnitude larger
that others, it might dominate the objective function and make the
estimator unable to learn from other features correctly as expected.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices by passing
<code>with_mean=False</code> to avoid breaking the sparsity structure of the data.</p>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_scaler&gt;</code>.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>copy</code> : boolean, optional, default True</p>
<p>If False, try to avoid a copy and do inplace scaling instead.
This is not guaranteed to always work inplace; e.g. if the data is
not a NumPy array or scipy.sparse CSR matrix, a copy may still be
returned.</p>
</li>
<li>
<p><code>with_mean</code> : boolean, True by default</p>
<p>If True, center the data before scaling.
This does not work (and will raise an exception) when attempted on
sparse matrices, because centering them entails building a dense
matrix which in common use cases is likely to be too large to fit in
memory.</p>
</li>
<li>
<p><code>with_std</code> : boolean, True by default</p>
<p>If True, scale the data to unit variance (or equivalently,
unit standard deviation).</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>scale_</code> : ndarray or None, shape (n_features,)</p>
<p>Per feature relative scaling of the data. This is calculated using
<code>np.sqrt(var_)</code>. Equal to <code>None</code> when <code>with_std=False</code>.</p>
<p>.. versionadded:: 0.17
<em>scale_</em></p>
</li>
<li>
<p><code>mean_</code> : ndarray or None, shape (n_features,)</p>
<p>The mean value for each feature in the training set.
Equal to <code>None</code> when <code>with_mean=False</code>.</p>
</li>
<li>
<p><code>var_</code> : ndarray or None, shape (n_features,)</p>
<p>The variance for each feature in the training set. Used to compute
<code>scale_</code>. Equal to <code>None</code> when <code>with_std=False</code>.</p>
</li>
<li>
<p><code>n_samples_seen_</code> : int or array, shape (n_features,)</p>
<p>The number of samples processed by the estimator for each feature.
If there are not missing samples, the <code>n_samples_seen</code> will be an
integer, otherwise it will be an array.
Will be reset on new calls to fit, but increments across
<code>partial_fit</code> calls.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; data = [[0, 0], [0, 0], [1, 1], [1, 1]]
&gt;&gt;&gt; scaler = StandardScaler()
&gt;&gt;&gt; print(scaler.fit(data))
StandardScaler()
&gt;&gt;&gt; print(scaler.mean_)
[0.5 0.5]
&gt;&gt;&gt; print(scaler.transform(data))
[[-1. -1.]
[-1. -1.]
[ 1.  1.]
[ 1.  1.]]
&gt;&gt;&gt; print(scaler.transform([[2, 2]]))
[[3. 3.]]
</code></pre>
<p><strong>See also</strong></p>
<p>scale: Equivalent function without the estimator API.</p>
<pre><code>:class:`sklearn.decomposition.PCA`
Further removes the linear correlation across features with 'whiten=True'.
</code></pre>
<p><strong>Notes</strong></p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
    transform.</p>
<pre><code>We use a biased estimator for the standard deviation, equivalent to
`numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to
affect model performance.

For a comparison of the different scalers, transformers, and normalizers,
see :ref:`examples/preprocessing/plot_all_scaling.py
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;`.
</code></pre>
<h3 id="methods_29">Methods</h3>
<hr>

<p><em>fit(X, y=None)</em></p>
<p>Compute the mean and std to be used for later scaling.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape [n_samples, n_features]</p>
<p>The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p>
<p>y
Ignored</p>
</li>
</ul>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : bool, default=True</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.</p>
</li>
</ul>
<hr>

<p><em>inverse_transform(X, copy=None)</em></p>
<p>Scale back the data to the original representation</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape [n_samples, n_features]</p>
<p>The data used to scale along the features axis.</p>
</li>
<li>
<p><code>copy</code> : bool, optional (default: None)</p>
<p>Copy the input X or not.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_tr</code> : array-like, shape [n_samples, n_features]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>partial_fit(X, y=None)</em></p>
<p>Online computation of mean and std on X for later scaling.</p>
<p>All of X is processed as a single batch. This is intended for cases
when :meth:<code>fit</code> is not feasible due to very large number of
<code>n_samples</code> or because X is read from a continuous stream.</p>
<p>The algorithm for incremental mean and std is given in Equation 1.5a,b
in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. "Algorithms
for computing the sample variance: Analysis and recommendations."
The American Statistician 37.3 (1983): 242-247:</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape [n_samples, n_features]</p>
<p>The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p>
</li>
<li>
<p><code>y</code> : None</p>
<p>Ignored.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Transformer instance.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : object</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X, copy=None)</em></p>
<p>Perform standardization by centering and scaling</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape [n_samples, n_features]</p>
<p>The data used to scale along the features axis.</p>
</li>
<li>
<p><code>copy</code> : bool, optional (default: None)</p>
<p>Copy the input X or not.</p>
</li>
</ul>
<h2 id="minmax_scaling">minmax_scaling</h2>
<p><em>minmax_scaling(X, columns, min_val=0, max_val=1)</em></p>
<p>In max scaling of pandas DataFrames.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>array</code> : pandas DataFrame, shape = [n_rows, n_columns].</p>
</li>
<li>
<p><code>columns</code> : array-like, shape = [n_columns]</p>
<p>Array-like with column names, e.g., ['col1', 'col2', ...]
or column indices [0, 2, 4, ...]</p>
</li>
<li>
<p><code>min_val</code> : <code>int</code> or <code>float</code>, optional (default=<code>0</code>)</p>
<p>minimum value after rescaling.</p>
</li>
<li>
<p><code>max_val</code> : <code>int</code> or <code>float</code>, optional (default=<code>1</code>)</p>
<p>maximum value after rescaling.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>df_new</code> : pandas DataFrame object.</p>
<p>Copy of the array or DataFrame with rescaled columns.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>For usage examples, please see
[http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.](http://jaisenbe58r.github.io/mlearner/user_guide/preprocessing/minmax_scaling/.)


adapted from
https://github.com/rasbt/mlxtend/blob/master/mlxtend/preprocessing/scaling.py
Author: Sebastian Raschka &lt;sebastianraschka.com&gt;
License: BSD 3 clause
</code></pre></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2018-2022 <a href="https://www.linkedin.com/in/jaisenbe">Jaime Sendra</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../js/jquery-1.10.2.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../..';
    </script>
    <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
    <script src="../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../mathjaxhelper.js"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
